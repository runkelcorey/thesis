---
bibliography: bib/thesis.bib
csl: csl/chicago-note-bibliography.csl
output:
  pdf_document:
    keep_tex: true
  html_document: default
  word_document: default
---
# Effects of the Neighborhood Stabilization Program on Voting {#outcome}

```{r libs, include=FALSE}
library(tidyverse)
library(knitr)
library(stargazer)
library(kableExtra)
library(sf)
library(betareg)
options(scipen = 9999, digits = 2, knitr.graphics.auto_pdf = TRUE)
knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",")
})
wide <- read_csv("wide.csv")
```

Complete data were available for 27,098 census tracts, covering more than half of the inhabited census tracts of 24 states, and more than half of the tracts where a self-described member of the Tea Party sought election.
Most of the census tracts missing belonged to states where connecting voting returns with census geography was infeasible.
For instance, Michigan does not make clear the links between a voting tabulation district (VTD) as the Census Bureau defines it, and the county-precinct-ward system the state uses to publicize its results.
For 15 other states, including Illinois, elections are so devolved that a state-wide election aggregation would have taken days to collect.

Since 1990, the Census Bureau has delineated census blocks covering the entire United States, standardizing units of analysis and making trivial the aggregation of data at various granularity.
While much of this analysis relies on data collected in 2010 census geographies, some key variables---including voting returns---were originally collected at a different geography.
Translating these data to the census-tract level was fundamental to my analysis, so it is important that I describe the relationships between statistical geographies as well as my process of translation.

## Relationships between statistical geographies {#census-geography}

Census geography runs as follows.
The basic unit, blocks, were originally designed just for Census takers to walk, and were constrained by physical boundaries difficult or illogical to cross.
However, since the Bureau undertook to cover the *entire* United States with census blocks, there are millions of census blocks with no inhabitants, covering lakes, parks, and barren landscapes; this fact will become important shortly.
Blocks are then aggregated into census tracts containing between 1,200 and 8,000 people.
Tracts are the smallest unit for which American Community Survey data---a continuously-run telephone survey that collects additional demographic data such as median household income and educational attainment---are published.
Census tracts sit inside counties and then inside states; unlike tracts and blocks, county boundaries are also legal jurisdictions and therefore rarely change.
See Figure \@ref(fig:geography) for the Census Bureau's graphical representation.[@lemery2020united]

```{r geography, out.width=c('50%','45%'), fig.align='center', fig.cap="Census geography relationships.", fig.subcap=c("To-scale breakdown of nested census geography, with street names.", "Organizational hierarchy of different geographies."), echo=FALSE, dev='pdf'}
include_graphics(c("figure/census_small_area_geography2.jpg", "figure/geo_hierarchy.png"))
```

While tracts and blocks were *designed* to be semi-permanent, acting as the basis for other, non-Census areas, in practice their shapes shift with population changes.
These shifts mean that: (a) not all 2000 tracts and 2010 tracts are congruent (though many are); and (b) non-Census areas (such as state-designed voting precincts) can cut census blocks.
Since these Census Bureau does not make public the responses of individual persons or homes until several decades after, placing each record in its appropriate area is impossible.
Rather, ecological methods approximate the distribution of persons, votes, or homes among geographies.
Ecological methods assume that persons, votes, or homes are equally distributed throughout an area: ecological methods would assume, for instance, that since six percent of Americans are millionaires, then six out of every hundred persons sampled---no matter their neighborhood---would also be millionaires.
Strictly speaking, ecological methods are logical fallacies of de-composition, of taking the whole for the part.
However, guided by the right principles, ecological methods can be perfectly valid statistical tools.

The first principle is that smaller geographies are better.
Take for example tract 12099005947, a nearly-optimal tract of 4,406 people in Palm Beach County.
The owner occupation rate is 97%, and 88% of the residents are aged 65 or older.
However, Palm Beach County entire contains tracts with as low as 4% 65-and-up, and owner occupancy rates around 33%.
Taking the county for the tract would poorly represent the diversity within Palm Beach, smoothing out the nuances that differentiate one neighborhood's politics from the next.
Zooming in on census tracts improves the accuracy of ecological methods, allowing for a fuller picture.

The second principle is that errors should be distributed evenly.
Errors here refer mainly to one party's votes that are misplaced among another party's voters, a result of the process by which voter tabulation districts must be decomposed and recomposed in order to translate non--2010 Census geography into 2010 Census geography.
This assumption may not always hold in my data: the history of American urban planning has shown that physical barriers---the same used to bound census blocks---often bind communities in more ways than one.
But since census tracts are also (if more weakly) constrained by physical boundaries, the aggregation of census blocks into tracts ought to be roughly consistent with the physical construction of communities by planners.
Additionally, most voting precincts do not cut tracts.
This means that the nightmare problem of gerrymandering deliberately undermining the assumption of evenly-distributed errors should be a moot point.
Gerrymandering divides *districts* into a biased collection of precincts, it does not redraw precinct lines.
Since my analysis deals with already-made and locally-created voting precincts, it skirts this particular problem potentially befalling analyses that begin at the county or Congressional-district level.

## Data collection and aggregation

I built my data almost exclusively from official statistics and estimates.
Given that most of my sources would eventually lead back to the Census Bureau, which covers the entire United States, I knew that the factors limiting my coverage would lie outside the Census Bureau.
Collecting and translating precinct-level voting data to census tracts proved to be the most limited and time-consuming aspect of this process.
I began by downloading precinct-level voting returns from the Harvard Election Data Archive (HEDA).[@ansolabehere2014precinctlevel]
Started in 2008 by political scientists, this database compiled voting returns from most states and reported results for state and national races in a standardized format.

These figures were then wedded to files specifying the geographic boundaries of each voting precinct within a state.
At this stage saw the complete loss of several states' data as some systems used to identify precincts at the state-level were inconsistent with Census Bureau naming conventions.
For each state, I looked for an isomorphic mapping from state-level naming to the standardized naming of the Census Bureau or Harvard Election Data Archive, and only for links where the match was clear were the data used.
Case in point was Maryland: the voting returns data clearly contained every single specified tract in Maryland, but matching algorithms could only identify a few hundred of the several thousand voting districts.
Geographic files came primarily from the Census Bureau's TIGER/Line redistricting project, the official database for all Census geography,[@20122010] via the Election-Geodata mapping project, an open-source repository for redistricting data,[@kelso2020nvkelso] though, as alluded to above, some states' geographic files were also compiled by HEDA.

Translating the voting precincts to Census geography was a complicated process of decomposition and recomposition.
Since Census tracts often straddle two voting precincts, distributing votes to particular tracts relies on ecological methods, essentially peeling off the part of a precinct lying in one tract and stitching it together with parts of the other precincts that also coincide with a tract.
This process generates Frankenstein tracts, where 20% of one precinct's votes are summed with 100% of a second precinct's votes and 3% of a third precinct's votes, depending on how much of a precinct coincides with a tract.
Since the voting records of these tracts are purely statistical constructions, it is perfectly fine that one have fractions of votes.
Take again, for example, our tract 12099005947 in Palm Beach County Florida: it recorded 732.00 Republican votes out of 3114.00 total votes in the 2010 Congressional race.
But it's neighbor, tract 12099005949, recorded 461.85 Republican votes against 1414.25 total votes.
Figure \@ref(fig:palmbeach) shows how this geometry is possible.

```{r palmbeach, out.width='45%', fig.align='center', fig.cap="Voting precincts and census tracts in Palm Beach County, Florida.", fig.subcap=c("Without census tracts.", "With census tracts."), echo=FALSE, dev='pdf'}
include_graphics(c("figure/wotracts.png", "figure/withtracts.png"))
```

There are, however, more than one ways to cut a census tract.
The obvious way to slice census tracts is by geography: the spatial intersection forms the basis for dividing up votes.
The better way to slice census tracts is by voting-age population: the intersection of eligible people forms the basis for dividing up votes.
This method better leverages even more granular data that the Census Bureau publishes to partially overcome ecological approximations and account for differing population densities *within* tracts.
The way tracts in exurban and coastal areas are created necessitates this approach.
Ideal census tracts *are* fairly homogeneous in terms of density, as it is the goal of the Census Bureau to preserve neighborhoods and actual street blocks where possible.
In contrast, tracts containing blocks where population density begins to shift can be quite irregular.
Since tract size is constrained by population, tracts not only *can* subsume those zero-population blocks I mentioned earlier, but *must* subsume some uninhabited blocks.

Public Law 94-171 (PL 94-171) ensures that the Congressional districting mandate of equally-populated districts be met with small-area population counts.
In addition, requirements of the Voting Rights Act pressed states to consider the racial makeup of their Congressional districts.
Since these are governmental tabulations, the population counts were required to be public.
I drew from these data tables, comprising every block in the United States, in order to divide up census tracts.
The advantage from data granularity is large: half of the 11,166,336 census blocks in 2010 were smaller than a tenth of a square mile[@2015fcc, 1]---Charlottesville itself contains 803 census blocks, averaging 54.14 persons.[@20112010b]

Then, to distribute portions of voting precincts to tracts, I counted how many census blocks from each particular tract lay within each precinct.
For computational reasons, the relevant statistic here was the block's spatial center rather than its nuanced boundaries.
Since blocks are so small, and voting precincts are supposed to be fashioned from census blocks (known exceptions exist in a handful of states), using the entire boundaries of a block would likely have generated errors that had more to do with the resolution of downloadable mapping files than actual, in-practice boundaries.
Summing up the voting-age population (the census does not ask about citizenship status or felonious histories) of those blocks that lay within a particular precinct, and then comparing that figure to the total voting-age population of said precinct, allocates the percentage of votes from a precinct to a tract.
This method is represented formally in Equation \@ref(eq:vtd), where t represents a particular tract, p a precinct from the set P of precincts intersecting with that particular tract, and b a block from the set B of blocks within that particular precinct:

\begin{equation}
votes_{t} = \sum_{p=1}^{P \cap t} votes_p \cdot \frac{\sum_{b=1}^{B \cap t} VAP_b}{\sum_{b=1}^{B} VAP_b}
(\#eq:vtd)
\end{equation}

To recap, this process first decomposes precincts P into blocks B, and then recomposes precincts from tracts T each with particular allocations of votes according to their relative share of the total precinct population.

In this dataset, each tract's votes were calculated by this method, with the exception of Californian tracts.
The Redistricting Database for the State of California, hosted at the University of California Berkeley School of Law, had already performed a more precise version of this process using voting registration records.[@20112010]
Voter registration records allow researchers to locate each address---and thus each resident voter---precisely within tracts and precincts.
A more careful version of my analysis would implement such methods, as the time required to aggregate each state's registration records exceeded my timeframe.

A similar process of decomposition followed by recomposition was used for the Department of Housing and Urban Development's foreclosure data,[@2008neighborhood; @cody2010neighborhood; @defilippo2009nsp2] which was tabulated at the 2000 tract- and block group--level.
The Census Bureau publishes relationship files that precisely place the percentage of housing units within each tract and block group in their 2010 equivalents.
I first decomposed 2000 tracts by the percentage of housing units intersecting with a particular 2010 tract, and then recomposed those 2010 tract figures by allocating foreclosure starts and total housing units according to the percentage each 2010 tract contained.

Lastly, data from the 2010 US Religion Census[@grammich2018religion] and the Bureau of Labor Statistics[@2020local] is collected at the county-level.
Since tract geography follows county geography, I simply joined those county figures to each tract, so for each tract the county average was used.
All other data used were native to the 2010 tract level, without translation.
These data were primarily from the 2010 decennial census, with some additional information from the 2005-2009 American Community Survey.
American Community Survey data comes attached with margins of error, but, no other variables had these margins of error.
In the interest of time and observations, I took the Census Bureau at their word that errors were distributed evenly.

The only data natively at the 2010 tract level from outside the Census Bureau were house price indices calculated by the Federal Housing Finance Agency.
Those data were constructed from tens of millions of federally-financed home loans.
By virtue of that source, the indices are *only* composed of prime mortgages.
However, two factors work in my favor here.
First, significantly more prime mortgages than subprime mortgages defaulted during the foreclosure crisis.[@ferreira2015new]
Second, the FHFA's index only considers properties with at least 100 sales (and purchases).
This feature matters because housing prices are strongly spatial dependent: nearby homes with nonconforming mortgages will likely sell for similar amounts as homes with conforming mortgages.
Still, this limitation means that some tracts with high levels of nonconforming loans were ommitted.
There are many neighborhoods, for instance, with complete homogeneity of conforming or nonconforming loans, enclaves
often connected by mortgage brokers who handled large numbers of subprime loans or specific developments.[@dayenChainTitleHow2016]
The political behavior of these developments is interesting due to their uniformity, but beside the aims of this thesis.

## Data Analysis {#analysis}

My approach will be simple: I will test my assumption that the Neighborhood Stabilization Program increased housing prices; then, I will model the effect of the NSP on voting with and without home price controls.
If the NSP did raise home prices, then its presence ought to be associated with an increase in Republican voting over the model that controls for home prices.
A HUD evaluation of the second NSP round did not find strong evidence for an price increase, so I will only examine the effects of NSP1.
Additionally, I allow for the possibility that impacts on voting only occurred where housing was politically stigmatized by a Tea Party candidate, as Chapter \@ref(motive-opportunity) suggested.
To evaluate localized effects, I run additional models using only the Tea Party tracts.

### Did NSP1 increase home prices?

``` {r nsprice, echo=FALSE, results='asis', eval=TRUE}
mod1 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG + HICOST + SDQ + STATE, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
mod2 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG + HICOST + SDQ, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
mod3 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
stargazer(mod1, mod2, mod3, type = "latex", title = "Effect of NSP1 on Prices", omit = c("^STATE", "FORQ2:MORTOCC", "MORTOCC:FORQ3"), label = "tab:prices", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "N", "N")), digits = 4, no.space = T, covariate.labels = c(NA, "Labor risk", "2010 unemployment rate", "Median household income", "2009 foreclosure rate", "Mortgaged occupancy rate", "2010 forelcosure rate", "Population density (per sq.mi.)", "65-and-up \\%", "Tenure in home", "Squared tenure", "White \\%", "Black \\%", "Hispanic \\%", "Asian \\%", "Unemployment change `05--`10", "High-cost mortgage rate", "Seriously delinquent rate"), dep.var.labels = "Home price index change, 2007-2010")
```

Table \@ref(tab:prices) lists the effects of NSP1 on prices.
Additional models remove state-level fixed effects and variables that were included in the allocation formula for NSP1, and thus covary highly with which tracts actually received NSP1 funding.
To avoid price spillovers from interfering with measurement, I only included tracts which were at least 1 mile away from a tract receiving NSP1 funding.
The results are plain and robust to several possible covariates: tracts receiving NSP1 funding were associated with statistically significant home prices declines, estimated between one and two points lower, compared to tracts not receiving aid.

Results (not shown) of these models for NSP2 funding, allocated competitively within at-risk tracts, are similarly sobering.
The estimated negative impacts agree with results from a HUD evaluation of the Neighborhood Stabilization Program's second round of funding, which found insignificant-to-negative changes in home prices.[@spader2015evaluation]
Further, these models appear to be good predictors of home prices, acounting for 79% to 85% of total price variations among the 12,234 tracts included.
Diagnostic plots of the best model are available in Figures \@ref(fig:priceresid) and \@ref(fig:priceqq).

While this evidence drives a nail into the coffin of foreclosure relief programs directly supporting anti-relief candidates, it still leaves open questions about the validity of the labor risk--equity model of voting explored in Chapters \@ref(motive-opportunity) and \@ref(methods).
Continuing the approach laid out above yields answers to two questions.
First, *could* relief programs directly aid the efforts of anti-relief candidates?
Second, in more general terms, are the effects of housing price changes magnified by low levels of home equity or high levels of labor risk?

### Could relief programs directly aid anti-relief campaigns?

Table \@ref(tab:fullsample) lists the results of the full-sample models with and without accounting for prices.
If the NSP's primary effect was lowering prices, then we should expect that tracts targeted by the first round of the Neighborhood Stabilization Program saw lower levels of Republican voting after taking into account other related factors except price changes.
Then, in the model *including* the price data, there should be no significant impact of NSP funding, as the only targets of the program were home prices.
For the labor risk--equity model, in all trials there should be positive correlations between price changes and Republican voting, with augmented values where price changes refract through economic anxiety, as measured by high foreclosure rates (i.e. low equity) or risky employment (a.k.a. high unemployment variance).

```{r fullsample, echo=FALSE, results='asis', eval=FALSE}
mod4 <- lm(RPCT ~ NSP1 + ANXIETY + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, wide)
mod5 <- lm(RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, wide)
stargazer(mod4, mod5, type = "latex", title = "Linear regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:fullsample", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

However, in both models the presence of the Neighborhood Stabilization Program is associated with more than a percentage point higher Republican voting.
This fact is in spite of the negative price effects of the NSP.
There are two different conclusions to draw from this result.
On the one hand, one could reject the model's capacity to describe the impacts of specific economic and demographic variables on majoritarian voting behavior.

On the other hand, one could accept the model's validity, opening up the possibility that the NSP's primary political effect is not in its home equity impacts.
Here the question of model validity is important.
The point is not to predict vote outcomes, but to infer the effects of certain variables.
While prediction would be nice (and would be sufficient to validate its inferential power), all that need be true is that the unexplained variance be independent of the parameter(s) of interest.
For instance, there is evidence that subprime mortgage brokers lent to Black and Latin-American families at systematically higher rates than White families;[REFERENCE NEEDED] since race is also associated with Republican voting, I have included descriptive variables in my models.
For this reason I am not worried about fact that only half of the variation in Republican voting share is explained by my model.

With this understanding of model validity, 

Table \@ref(tab:fullsample) lists the results of the model with and without prices
Fixed effects are a sort of catch-all method to deal with unobserved characteristics particular to certain levels.
For instance, state laws governing taxation or the shape of voting precincts are not present in my dataset, so I employ state-level fixed effects to try and isolate these effects.
Mechanically, this method groups all observations belonging to each state as a single regressor.^[Due to the fact that 24 states are included in this analysis, I truncated the output in light of space. Almost all states had statistically-significant associated effects.]
While fixed-effects are standard fare in econometric analysis, I include both models because the assumptions of this fixed-effects model may not be met.
Namely, it presumes that all directly-relevant and observable predictors are present; as I will show later, these data may be too limited to fully explain the spatial correlation among the voting results.

The coefficients of most every control predictor are consistent with prior research, with two caveats.
Of particular importance, this model conforms with the literature connecting homeownership to conservative voting around the world, as the owner-occupied homeownership rate is positively associated with Republican vote share.
The 2010 unemployment rate and population density have the opposite signs that were expected: in my model, as the unemployment rate climbs, the Republican voting percentage falls; conversely, as the population density increases, so to does the vote share.
That being said, these are small effects; a (massive) 10-point rise in unemployment is associated here with just a 2.3-point rise in vote share.
For population density the impacts are even smaller.
The consistency of these impacts acts as a kind of eye test for the validity of this model, with the argument being that here are simply added predictors to an already-solid model.

Of interest to this thesis are the coefficients attached to the Neighborhood Stabilization Program, 2010 foreclosure rate, and change in home prices.
Against my hypothesis that foreclosure rates---a proxy for negative equity---would be negatively associated with Republican vote share, while home-price changes would be positively linked to Republican vote share, each regressor displays the *opposite* behavior.
Part of the price-change behavior seems to be absorbed by the state-level fixed effects, however.
The logic here is that there is correlation between Republican voting shares in nearby census tracts that covaries both with the particular state and with prices.
The nearness (or farness) of tracts is unobserved by this model, but may nonetheless contain important information linked to---but distinct from---price changes.
It is ambiguous what that information may be, however: it could align with financial data on equity or rates of seriously-delinquent mortgage payments, but alternatively, it could be socio-cultural, relating instead to irrational exuberance over price changes or perceptions of fortunate homeowners.

Separate from the effects of price changes and foreclosure rates, the Neighborhood Stabilization Program had a chronologically-dependent effect on Republican vote share.
Tracts targeted with the first round of grants (NSP1) were associated with a 1.75-point increase in Republican vote share, while the later rounds---NSP2 and NSP3---were associated with decreases in Republican vote shares after taking account of race, educational attainment, religious, and economic factors.
Since properties could not be purchased (let alone repaired or resold) before funds were granted, NSP3 (and to a lesser extent NSP2) tracts could not have seen financial benefit from the program.
I interpret this result as a strong evidence for the conclusion that the Neighborhood Stabilization Program, by supporting homeowner wealth, push voters rightward.
Why, though, would NSP2 and NSP3---without a robust advertising effort or partisan attachment---be associated with Democratic votes?
My theory is, again, unobserved variable bias.
NSP1 and NSP3 were targeted due to the risk of further foreclosures, associated with high-cost, high-leverage loans (most of which were subprime) and, therefore, mortgagees at the financial margins, who tend to vote more Democratic.

The effects of the Neighborhood Stabilization Program are sharpened by the presence of Tea Party politics.
Table \@ref(tab:justp) lists the results with and without state-level fixed effects for different subsets of the full sample, all of which saw races between self-avowed Tea Party candidates.
While the signs of coefficients attached to the NSP rounds remain the same, their significances vary.
This variance is likely due to sample size, as the number of tracts with winning candidates contained little more than a tenth of the total observations.
Throughout these models, most control variables remained entirely stable, with the unemployment rate and the proportion of residents 65 and older respectively losing and gaining statistical significance among models.

```{r justp, echo=FALSE, results='asis', eval=FALSE}
mod6 <- lm(RPCT ~ NSP1 + ADJ_FORQ*EMPLOYRISK + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE, filter(wide, RESULT != "EXTRA-TP"))
mod7 <- lm(RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE, filter(wide, RESULT != "EXTRA-TP"))
stargazer(mod6, mod7, type = "latex", title = "Linear regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:justp", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

The variables of interest were a mixed bag.
NSP1 in each model showed strong statistical basis for rejecting the null hypothesis in favor of a positive effect on Republican voting, while the second and third rounds of the Neighborhood Stabilization Program consistently showed a negative association with Republican voting shares, though with inconsistent significance.
Due to the ever-shrinking size of the dataset, I lean towards chalking this result up to an issue of size.
The price change and foreclosure rates never delivered a statistically-significant pair consistent with expectations, with little evidence that either has a determinate effect on voting.

### Limitations and proposed refinements {#limitations}

As stated above, these models were limited by several factors.
The three areas I focus on as most important are data quality, model fitness, and spatial dependence.
My data quality concerns are ever-present in natural-experiment methodologies.
In short, individual voting characteristics, more granular price data, and a fuller spread of census tracts could have aided the conclusivity of this evidence.
Additionally, individual-level observations would have avoided the ecological assumptions this analysis rests on.

The second question, of model fitness, leaves for more ambiguous refinements.
In inferential statistics, there is less of a need for a model to fit the data comprehensively.
On that count, the attached .40-.62 R^{2} values are not concerning.
However, analysis of residuals leaves something to be desired.
Figure \@ref(fig:linearesid) shows the residuals against fitted values for the full-sample, fixed-effects model.
Ideally, residuals show no conclusive pattern, and are independent against the fitted values.
Here, there is a clear inverse relationship framed by the bounds of the Republican voting share at 0 and 100 percent.
Linear models are not built to handle bounded response variables, though I used one for the ease of computation and interpretation.

``` {r linear, echo=FALSE, out.width='45%', fig.align='center', fig.cap="Diagnostic plots of the linear models.", fig.subcap=c("Residuals of full linear model.\\label{fig:linearesid}","Acutal vs. fitted quantiles of full linear model.\\label{fig:linearquant}")}
include_graphics(c("figure/linearesid.png", "figure/linearquant.png"))
```

In order to validate the results of these models, I also modeled Republican vote share by different distributions.
I settled on reporting results for regressions on the Beta distribution because of its flexibility and ability to approximate the distribution of Republican voting share.
The Beta distribution is a basic (but complicated) distribution used for response variables bounded between 0 and 1.
It easily incorporates changing variance and does not assume linearity, which is helpful when considering social interactions generally, and electoral data specifically.
As Figure \@ref(fig:linearquant) shows, the variance of actual versus fitted values skyrockets at the upper end of my model.

``` {r betaresid, echo=FALSE, out.width='90%', fig.align='center', fig.cap="Residuals of beta regression."}
include_graphics("figure/betaresid.png")
```

In contrast, the behavior of Figure \@ref(fig:betaresid) conforms more closely to an ideal distribution, with less-pronounced upper and lower bounds.
Results of the beta regressions can be seen in Table \@ref(tab:beta).
Coefficients are altogether similar to what the linear models predict, making me more secure in my belief of their validity.

```{r beta, echo=FALSE, results='asis', eval=FALSE}
mod8 <- betareg(ADJ_RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, wide)
mod9 <- betareg(ADJ_RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, filter(wide, RESULT != "EXTRA-TP"))
mod8$coefficients <- mod8$coefficients$mean*100
mod9$coefficients <- mod9$coefficients$mean*100
stargazer(mod8, mod9, type = "latex", title = "Beta regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:beta", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

Lastly, as mentioned, I believe these models were spatially-dependent, with biased the estimation of the home price effect on voting behavior.
I had originally planned to incorporate spatial autoregressive methods to correct for this spatial dependence, but limitations inherent to my data, as well as my own facility with such approaches, quashed that opportunity.
Nonetheless, I can virtually prove its existence in my models using standard tests of spatial correlation.

I first constructed a neighbor's matrix from geographic census tract files; this matrix tells **R** which tracts share an edge.
I then ran the residuals of each model (from a positivist interpretation, these are the unobserved variables) through Moran's I and Geary's C tests.
The similar tests look for spatial dependence respectively at the global and local levels.
Since this dataset is fractured, containing large discontiguities, Geary's C test will be the more appropriate measure; both are retained because the calculations are quick and similar.
Table \@ref(tab:spdep) displays the results of these tests, all of which reject the null hypothesis of no spatial dependence at the highest precision level **R** offers.

```{r spdep, echo=FALSE, message=FALSE}
spdep <- read_csv("data/voting/display/spdep.csv")
kable(spdep, "latex", booktabs = T, caption = "Results of various tests for spatial dependence. In all tests, the null hypothesis is spatially-independent.", align = 'c')
```

## Conclusion
In sum, there is strong evidence that recipients of the Neighborhood Stabilization Program's first round of grants voted more conservative in the 2010 elections, while subsequent rounds voted more liberal.
This fact can be explained by the timescale that the NSP operated on.
Other heretofore unexamined factors, such as home price level and foreclosure rate, show mixed results, though the strongest effects came as Tea Party politics stigmatized homeownership, foreclosure, and government relief programs.
