---
bibliography: bib/thesis.bib
csl: csl/chicago-note-bibliography.csl
output:
  pdf_document:
    keep_tex: true
  html_document: default
  word_document: default
---
# Effects of the Neighborhood Stabilization Program on Voting {#outcome}

```{r libs, include=FALSE}
library(tidyverse)
library(knitr)
library(stargazer)
library(kableExtra)
library(sf)
library(betareg)
options(scipen = 9999, digits = 2, knitr.graphics.auto_pdf = TRUE)
knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",")
})
wide <- read_csv("wide.csv")
```

Complete data were available for 27,098 census tracts, covering more than half of the inhabited census tracts of 24 states, and more than half of the tracts where a self-described member of the Tea Party sought election.
Most of the census tracts missing belonged to states where connecting voting returns with census geography was infeasible.
For instance, Michigan does not make clear the links between a voting tabulation district (VTD) as the Census Bureau defines it, and the county-precinct-ward system the state uses to publicize its results.
For 15 other states, including Illinois, elections are so devolved that a state-wide election aggregation would have taken days to collect.

Since 1990, the Census Bureau has delineated census blocks covering the entire United States, standardizing units of analysis and making trivial the aggregation of data at various granularity.
While much of this analysis relies on data collected in 2010 census geographies, some key variables---including voting returns---were originally collected at a different geography.
Translating these data to the census-tract level was fundamental to my analysis, so it is important that I describe the relationships between statistical geographies as well as my process of translation.

## Relationships between statistical geographies {#census-geography}

Census geography runs as follows.
The basic unit, blocks, were originally designed just for Census takers to walk, and were constrained by physical boundaries difficult or illogical to cross.
However, since the Bureau undertook to cover the *entire* United States with census blocks, there are millions of census blocks with no inhabitants, covering lakes, parks, and barren landscapes; this fact will become important shortly.
Blocks are then aggregated into census tracts containing between 1,200 and 8,000 people.
Tracts are the smallest unit for which American Community Survey data---a continuously-run telephone survey that collects additional demographic data such as median household income and educational attainment---are published.
Census tracts sit inside counties and then inside states; unlike tracts and blocks, county boundaries are also legal jurisdictions and therefore rarely change.
See Figure \@ref(fig:geography) for the Census Bureau's graphical representation.[@lemery2020united]

```{r geography, out.width=c('50%','45%'), fig.align='center', fig.cap="Census geography relationships.", fig.subcap=c("To-scale breakdown of nested census geography, with street names.", "Organizational hierarchy of different geographies."), echo=FALSE, dev='pdf'}
include_graphics(c("figure/census_small_area_geography2.jpg", "figure/geo_hierarchy.png"))
```

While tracts and blocks were *designed* to be semi-permanent, acting as the basis for other, non-Census areas, in practice their shapes shift with population changes.
These shifts mean that: (a) not all 2000 tracts and 2010 tracts are congruent (though many are); and (b) non-Census areas (such as state-designed voting precincts) can cut census blocks.
Since these Census Bureau does not make public the responses of individual persons or homes until several decades after, placing each record in its appropriate area is impossible.
Rather, ecological methods approximate the distribution of persons, votes, or homes among geographies.
Ecological methods assume that persons, votes, or homes are equally distributed throughout an area: ecological methods would assume, for instance, that since six percent of Americans are millionaires, then six out of every hundred persons sampled---no matter their neighborhood---would also be millionaires.
Strictly speaking, ecological methods are logical fallacies of de-composition, of taking the whole for the part.
However, guided by the right principles, ecological methods can be perfectly valid statistical tools.

The first principle is that smaller geographies are better.
Take for example tract 12099005947, a nearly-optimal tract of 4,406 people in Palm Beach County.
The owner occupation rate is 97%, and 88% of the residents are aged 65 or older.
However, Palm Beach County entire contains tracts with as low as 4% 65-and-up, and owner occupancy rates around 33%.
Taking the county for the tract would poorly represent the diversity within Palm Beach, smoothing out the nuances that differentiate one neighborhood's politics from the next.
Zooming in on census tracts improves the accuracy of ecological methods, allowing for a fuller picture.

The second principle is that errors should be distributed evenly.
Errors here refer mainly to one party's votes that are misplaced among another party's voters, a result of the process by which voter tabulation districts must be decomposed and recomposed in order to translate non--2010 Census geography into 2010 Census geography.
This assumption may not always hold in my data: the history of American urban planning has shown that physical barriers---the same used to bound census blocks---often bind communities in more ways than one.
But since census tracts are also (if more weakly) constrained by physical boundaries, the aggregation of census blocks into tracts ought to be roughly consistent with the physical construction of communities by planners.
Additionally, most voting precincts do not cut tracts.
This means that the nightmare problem of gerrymandering deliberately undermining the assumption of evenly-distributed errors should be a moot point.
Gerrymandering divides *districts* into a biased collection of precincts, it does not redraw precinct lines.
Since my analysis deals with already-made and locally-created voting precincts, it skirts this particular problem potentially befalling analyses that begin at the county or Congressional-district level.

## Data collection and aggregation

I built my data almost exclusively from official statistics and estimates.
Given that most of my sources would eventually lead back to the Census Bureau, which covers the entire United States, I knew that the factors limiting my coverage would lie outside the Census Bureau.
Collecting and translating precinct-level voting data to census tracts proved to be the most limited and time-consuming aspect of this process.
I began by downloading precinct-level voting returns from the Harvard Election Data Archive (HEDA).[@ansolabehere2014precinctlevel]
Started in 2008 by political scientists, this database compiled voting returns from most states and reported results for state and national races in a standardized format.

These figures were then wedded to files specifying the geographic boundaries of each voting precinct within a state.
At this stage saw the complete loss of several states' data as some systems used to identify precincts at the state-level were inconsistent with Census Bureau naming conventions.
For each state, I looked for an isomorphic mapping from state-level naming to the standardized naming of the Census Bureau or Harvard Election Data Archive, and only for links where the match was clear were the data used.
Case in point was Maryland: the voting returns data clearly contained every single specified tract in Maryland, but matching algorithms could only identify a few hundred of the several thousand voting districts.
Geographic files came primarily from the Census Bureau's TIGER/Line redistricting project, the official database for all Census geography,[@20122010] via the Election-Geodata mapping project, an open-source repository for redistricting data,[@kelso2020nvkelso] though, as alluded to above, some states' geographic files were also compiled by HEDA.

Translating the voting precincts to Census geography was a complicated process of decomposition and recomposition.
Since Census tracts often straddle two voting precincts, distributing votes to particular tracts relies on ecological methods, essentially peeling off the part of a precinct lying in one tract and stitching it together with parts of the other precincts that also coincide with a tract.
This process generates Frankenstein tracts, where 20% of one precinct's votes are summed with 100% of a second precinct's votes and 3% of a third precinct's votes, depending on how much of a precinct coincides with a tract.
Since the voting records of these tracts are purely statistical constructions, it is perfectly fine that one have fractions of votes.
Take again, for example, our tract 12099005947 in Palm Beach County Florida: it recorded 732.00 Republican votes out of 3114.00 total votes in the 2010 Congressional race.
But it's neighbor, tract 12099005949, recorded 461.85 Republican votes against 1414.25 total votes.
Figure \@ref(fig:palmbeach) shows how this geometry is possible.

```{r palmbeach, out.width='45%', fig.align='center', fig.cap="Voting precincts and census tracts in Palm Beach County, Florida.", fig.subcap=c("Without census tracts.", "With census tracts."), echo=FALSE, dev='pdf'}
include_graphics(c("figure/wotracts.png", "figure/withtracts.png"))
```

There are, however, more than one ways to cut a census tract.
The obvious way to slice census tracts is by geography: the spatial intersection forms the basis for dividing up votes.
The better way to slice census tracts is by voting-age population: the intersection of eligible people forms the basis for dividing up votes.
This method better leverages even more granular data that the Census Bureau publishes to partially overcome ecological approximations and account for differing population densities *within* tracts.
The way tracts in exurban and coastal areas are created necessitates this approach.
Ideal census tracts *are* fairly homogeneous in terms of density, as it is the goal of the Census Bureau to preserve neighborhoods and actual street blocks where possible.
In contrast, tracts containing blocks where population density begins to shift can be quite irregular.
Since tract size is constrained by population, tracts not only *can* subsume those zero-population blocks I mentioned earlier, but *must* subsume some uninhabited blocks.

Public Law 94-171 (PL 94-171) ensures that the Congressional districting mandate of equally-populated districts be met with small-area population counts.
In addition, requirements of the Voting Rights Act pressed states to consider the racial makeup of their Congressional districts.
Since these are governmental tabulations, the population counts were required to be public.
I drew from these data tables, comprising every block in the United States, in order to divide up census tracts.
The advantage from data granularity is large: half of the 11,166,336 census blocks in 2010 were smaller than a tenth of a square mile[@2015fcc, 1]---Charlottesville itself contains 803 census blocks, averaging 54.14 persons.[@20112010b]

Then, to distribute portions of voting precincts to tracts, I counted how many census blocks from each particular tract lay within each precinct.
For computational reasons, the relevant statistic here was the block's spatial center rather than its nuanced boundaries.
Since blocks are so small, and voting precincts are supposed to be fashioned from census blocks (known exceptions exist in a handful of states), using the entire boundaries of a block would likely have generated errors that had more to do with the resolution of downloadable mapping files than actual, in-practice boundaries.
Summing up the voting-age population (the census does not ask about citizenship status or felonious histories) of those blocks that lay within a particular precinct, and then comparing that figure to the total voting-age population of said precinct, allocates the percentage of votes from a precinct to a tract.
This method is represented formally in Equation \@ref(eq:vtd), where t represents a particular tract, p a precinct from the set P of precincts intersecting with that particular tract, and b a block from the set B of blocks within that particular precinct:

\begin{equation}
votes_{t} = \sum_{p=1}^{P \cap t} votes_p \cdot \frac{\sum_{b=1}^{B \cap t} VAP_b}{\sum_{b=1}^{B} VAP_b}
(\#eq:vtd)
\end{equation}

To recap, this process first decomposes precincts P into blocks B, and then recomposes precincts from tracts T each with particular allocations of votes according to their relative share of the total precinct population.

In this dataset, each tract's votes were calculated by this method, with the exception of Californian tracts.
The Redistricting Database for the State of California, hosted at the University of California Berkeley School of Law, had already performed a more precise version of this process using voting registration records.[@20112010]
Voter registration records allow researchers to locate each address---and thus each resident voter---precisely within tracts and precincts.
A more careful version of my analysis would implement such methods, as the time required to aggregate each state's registration records exceeded my timeframe.

A similar process of decomposition followed by recomposition was used for the Department of Housing and Urban Development's foreclosure data,[@2008neighborhood; @cody2010neighborhood; @defilippo2009nsp2] which was tabulated at the 2000 tract- and block group--level.
The Census Bureau publishes relationship files that precisely place the percentage of housing units within each tract and block group in their 2010 equivalents.
I first decomposed 2000 tracts by the percentage of housing units intersecting with a particular 2010 tract, and then recomposed those 2010 tract figures by allocating foreclosure starts and total housing units according to the percentage each 2010 tract contained.

Lastly, data from the 2010 US Religion Census[@grammich2018religion] and the Bureau of Labor Statistics[@2020local] is collected at the county-level.
Since tract geography follows county geography, I simply joined those county figures to each tract, so for each tract the county average was used.
All other data used were native to the 2010 tract level, without translation.
These data were primarily from the 2010 decennial census, with some additional information from the 2005-2009 American Community Survey.
American Community Survey data comes attached with margins of error, but, no other variables had these margins of error.
In the interest of time and observations, I took the Census Bureau at their word that errors were distributed evenly.

The only data natively at the 2010 tract level from outside the Census Bureau were house price indices calculated by the Federal Housing Finance Agency.
Those data were constructed from tens of millions of federally-financed home loans.
By virtue of that source, the indices are *only* composed of prime mortgages.
However, two factors work in my favor here.
First, significantly more prime mortgages than subprime mortgages defaulted during the foreclosure crisis.[@ferreira2015new]
Second, the FHFA's index only considers properties with at least 100 sales (and purchases).
This feature matters because housing prices are strongly spatial dependent: nearby homes with nonconforming mortgages will likely sell for similar amounts as homes with conforming mortgages.
Still, this limitation means that some tracts with high levels of nonconforming loans were ommitted.
There are many neighborhoods, for instance, with complete homogeneity of conforming or nonconforming loans, enclaves
often connected by mortgage brokers who handled large numbers of subprime loans or specific developments.[@dayenChainTitleHow2016]
The political behavior of these developments is interesting due to their uniformity, but beside the aims of this thesis.

## Data Analysis {#analysis}

My approach will be simple: I will test my assumption that the Neighborhood Stabilization Program increased housing prices; then, I will model the effect of the NSP on voting with and without home price controls.
If the NSP did raise home prices, then its presence ought to be associated with an increase in Republican voting over the model that controls for home prices.
A HUD evaluation of the second NSP round did not find strong evidence for an price increase, so I will only examine the effects of NSP1.
Additionally, I allow for the possibility that impacts on voting only occurred where housing was politically stigmatized by a Tea Party candidate, as Chapter \@ref(motive-opportunity) suggested.
To evaluate localized effects, I run additional models using only the Tea Party tracts.

### Did NSP1 increase home prices?

``` {r nsprice, echo=FALSE, results='asis', eval=TRUE}
mod1 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG + HICOST + SDQ + STATE, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
mod2 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG + HICOST + SDQ, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
mod3 <- lm(PRICECHG0710 ~ NSP1 + EMPLOYRISK + UNEM10 + MEDHHI + FORQ2*MORTOCC + FORQ3*MORTOCC + DENSITY + OLD + TENURE + TENURE2 + VAP_W + VAP_B + VAP_H + VAP_A + UNEMCHG, filter(wide, DISTNSP1 > 1, DISTNSP1 < 5))
stargazer(mod1, mod2, mod3, type = "latex", title = "Effect of NSP1 on Prices", omit = c("^STATE", "FORQ2:MORTOCC", "MORTOCC:FORQ3"), label = "tab:prices", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "N", "N")), digits = 4, no.space = T, covariate.labels = c(NA, "Labor risk", "2010 unemployment rate", "Median household income", "2009 foreclosure rate", "Mortgaged occupancy rate", "2010 forelcosure rate", "Population density (per sq.mi.)", "65-and-up \\%", "Tenure in home", "Squared tenure", "White \\%", "Black \\%", "Hispanic \\%", "Asian \\%", "Unemployment change `05--`10", "High-cost mortgage rate", "Seriously delinquent rate"), dep.var.labels = "Home price index change, 2007-2010")
```

Table \@ref(tab:prices) lists the effects of NSP1 on prices.
Additional models remove state-level fixed effects and variables that were included in the allocation formula for NSP1, and thus covary highly with which tracts actually received NSP1 funding.
To avoid price spillovers from interfering with measurement, I only included tracts which were at least 1 mile away from a tract receiving NSP1 funding.
The results are plain and robust to several possible covariates: tracts receiving NSP1 funding were associated with statistically significant home prices declines, estimated between one and two points lower, compared to tracts not receiving aid.

Results (not shown) of these models for NSP2 funding, allocated competitively within at-risk tracts, are similarly sobering.
The estimated negative impacts agree with results from a HUD evaluation of the Neighborhood Stabilization Program's second round of funding, which found insignificant-to-negative changes in home prices.[@spader2015evaluation]
Further, these models appear to be good predictors of home prices, acounting for 79% to 85% of total price variations among the 12,234 tracts included.
Diagnostic plots of the best model are available in Figures \@ref(fig:priceresid) and \@ref(fig:priceqq).

While this evidence drives a nail into the coffin of foreclosure relief programs directly supporting anti-relief candidates, it still leaves open questions about the validity of the labor risk--equity model of voting explored in Chapters \@ref(motive-opportunity) and \@ref(methods).
Continuing the approach laid out above yields answers to two questions.
First, *could* relief programs directly aid the efforts of anti-relief candidates?
Second, in more general terms, are the effects of housing price changes magnified by low levels of home equity or high levels of labor risk?

### Voting Impacts of the NSP and Price Changes {#impacts}

Table \@ref(tab:fullsample) lists the results of the full-sample models with and without accounting for prices.
If the NSP's primary effect was lowering prices, then we should expect that tracts targeted by the first round of the Neighborhood Stabilization Program saw lower levels of Republican voting after taking into account other related factors except price changes.
Then, in the model *including* the price data, there should be no significant impact of NSP funding, as the only targets of the program were home prices.
For the labor risk--equity model, in all trials there should be positive correlations between price changes and Republican voting, with augmented values where price changes refract through economic anxiety, as measured by high foreclosure rates (i.e. low equity) or risky employment (a.k.a. high unemployment variance).

```{r fullsample, echo=FALSE, results='asis', eval=FALSE}
mod4 <- lm(RPCT ~ NSP1 + ANXIETY + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, wide)
mod5 <- lm(RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, wide)
stargazer(mod4, mod5, type = "latex", title = "Linear regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:fullsample", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

However, in both models the presence of the Neighborhood Stabilization Program is associated with approximately one percentage point higher Republican voting.
This fact is in spite of the negative price effects of the NSP.
There are two different conclusions to draw from this result: one could either accept the model's validity and direct attention to the Neighborhood Stabilization Program's progress by 2010; or one could  reject the model's capacity to describe the impacts of specific economic and demographic variables on majoritarian voting behavior.
But doing the latter would also reject the findings of this model that conform to theoretical expectations as well as prior research.
Down the line, from residential tenure through the weighted portion of white people with less education than a college degree, demographic factors identified by prior research as impacting the outcome of elections in particular directions were similarly associated in my model.

Moreover, key features of the labor risk--equity model of political behavior found strong evidence in model 2.
The interaction effects between price changes, foreclosure rates, and labor risk are of interest here (uninteracted forms are provided for completeness and their effects are not predicted by the labor risk--equity literature).
The magnifying effects of labor risk and foreclosure rate on price changes were directly proportional.
They were---in addition to most every other variable---statistically-significant at the 1% level.
For instance, in our Palm Beach County tract 12099005947, my model estimated a 5.7-point increase in Republican vote share due to the combination of home price decline, foreclosure rate, and variance of employment, all in a non--Tea Party district that voted heavily Democratic.
Both the triple interaction between prices, foreclosures, and labor risk, as well as the price change--foreclosure rate interaction hold positive coefficients, consistent with the model's prediction that low-equity and high-labor risk combine to decrease preferences for social insurance, tied in the United States to higher taxation.

But curiously, the interaction between price change and labor risk carries an inverse relationship with Republican voting.
In English, this result means that risky employment and increasing prices actually causes more to vote Democratic (or, technically, non-Republican) even as both labor risk and the triple interaction with prices and foreclosures are directly associated with Republican voting.
This result was robust to the addition and subtraction of several covariates and subsets of the observations (results not shown).
I account for this with post-crisis literature which additional difficulties associated with securing home equity lines of credit (HELOCs) for individuals with risky occupations.[@mota2015spatial, Table 1]
Thus, rather than this negative association representing an inconsistency between predicted and actual effects of increased equity, it could be the case that incomplete credit markets prevented individuals with highly-risky employment from behaving as they would prefer.
In sum, the labor risk--equity model and prior literature on Republican voting behavior broadly agree with my regression results on the full sample of observations.

Because of these reasons, I urge acceptance of the model's capacity to understand the effects of certain economic variables on partisan voting behavior.
Here it is important to understand this specific sense of model validity.
The point here is not to predict vote outcomes, but to infer the effects of certain variables.
While prediction would be nice (and would be sufficient to validate a model's inferential power), all that need be true is that the unexplained variance be independent of the parameter(s) of interest.
For instance, there is evidence that subprime mortgage brokers lent to Black and Latin-American families at systematically higher rates than White families;[@dymski2013race; @faber2013race] since race is also associated with Republican voting, I have included descriptive variables in my models.
Elsewhere, research has identified household factors---namely size, and age of parents---that push Evangelical and Mormon applicants to become early, unqualified entrants to the mortgage market, and therefore more susceptible to application rejections and subprime lending.[@lown2005educating]
Though I am somewhat worried about data quality with regards to ecological methods, the care taken to remove unobserved variable bias and the congruence of my results with expectations leads me to confidence in my *model*, and explains why I do not worry about fact that only half of the variation in Republican voting share is explained by my model.

As such, attention should be directed instead towards the NSP.
It seems that, since the NSP is associated with higher rates of Republican voting in the face of negative price effects, cultural (rather than economic) factors may have been at play.
One explanatory theory is the patronage model of voting, otherwise known as you scratch our back, and we'll scratch yours.
Table \@ref(tab:compnsp) compares how each of the NSP rounds fared with respect to Republican votes.
The first round saw increased levels of Republican voting, while rounds two and three saw decreases in Republican vote share.
I excluded the second and third NSP rounds because, as of July 2011, respectively 20.6% and 0.4% of funds had been expended from NSP2 and NSP3.[@2011hud; @2011huda]
Thus, any perceived effects could not been due to the price effects sought by the program.
Though NSP1 had expended 43.4% of funds and fully committed its allocations to grantees by September 2010,[@hud2010] the analysis of housing prices above demonstrates that the program had not yet (if it had eventually) raised prices for recipients.
The distinctive characteristics of the three rounds, then, may not have been their efficacy, but rather their association with administrations: NSP1 was authorized by the George W. Bush administration, while NSP2 and NSP3 were administered by the Barack Obama administration.
Further research is required to understand these phenomena, if they are in fact present.[^Admittedly it seems unlikely that such neighborhoods---likely already targeted by other government programs---would feel such attachment to a presidential administration due to the Neighborhood Stabilization Program]

A possible reason for the primacy of cultural factors here is that social insurance and taxation were not so politically salient in non--Tea Party districts.
This possibility is readily assimilable to the work done in previous chapters, as it simply would be a matter of degree separating the behavior of Tea Party and non--Tea Party districts.
Table \@ref(tab:justp) shows the results of the same model above, but applied only to tracts in which a self-described member of the Tea Party ran for election.
In these trials, more pronounced home price effects should be expected, though it may also be possible that "deadbeat" homeowners are further stigmatized by Tea Party candidates, leading to more conservatizing effects of increased foreclosure rates.

```{r justp, echo=FALSE, results='asis', eval=FALSE}
mod6 <- lm(RPCT ~ NSP1 + ANXIETY + ADJ_FORQ + EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, filter(wide, RESULT != "EXTRA-TP"))
mod7 <- lm(RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, filter(wide, RESULT != "EXTRA-TP"))
stargazer(mod6, mod7, type = "latex", title = "Linear regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:justp", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

These trials offer promising results but less statistical significance.
First, the evidence that NSP1 had any effect on voting is far from conclusive, with statistically insignificant associations between round one funding and Republican vote shares.
Second, home price interaction terms are significant and carry the same signs as in trials run on the full slate of observations, but insignificant when uninteracted.
Third, the foreclosure rate switches signs when combined with the effects of home prices.
This switch means that *apart from their effects on prices* foreclosures are associated with increased Republican voting, but when those [negative] price effects are included, voters choose Democratic candidates more.
This finding agrees with the narrative that Tea Party candidates cast foreclosed homeowners as irresponsible and blame-worthy neighbors.

Explaining the cultural dynamics of this phenomenon (and teasing out its existence) opens opportunities for further research, but I present one theory now.
Eagle-eyed readers will have noted that, while the foreclosure rate and population density were included in Section \@ref(model), the interaction between them was left unexplained.
I have included this term to measure sociological effects of foreclosures, namely social contact theory, which posits that contact with an Other causes members of the in-group to sympathize with said Other.
In this case, that Other is foreclosed homeowners.
Where density is low, it may be possible to avoid seeing or knowing one of these "deadbeats", but as densities (and foreclosure rates) rise, it becomes less and less possible to assimilate ideas of irresponsibility and blame with people that one knows personally.
While the coefficient attached to the foreclosure rate--population density interaction term is small, it was statistically significant in every trial I ran.
Further, population density carries an enormous range of values; while most of these predictors are bounded between 0 and 100 percent, population density ranges from 0 to nearly 80,000.
As such, the interaction term ranges from 0 to `range(wide$ADJ_FORQ*wide$DENSITY)[2]`, meaning that effects could be quite large at the upper end.


### Limitations and proposed refinements {#limitations}

However, even with all these statistically-significant terms, there are questions of model adequacy that I am poorly-equipped to address.
These models were limited by several factors, but the three areas I focus on as most important are data quality, model fitness, and spatial dependence.
My data quality concerns are ever-present in natural-experiment methodologies.
In short, individual voting characteristics, more granular price data, and a fuller spread of census tracts could have aided the conclusivity of this evidence.
Additionally, using individual-level demographics and vote results would have avoided the ecological assumptions this analysis rests on.

The second question, of model fitness, leaves for more ambiguous refinements.
In inferential statistics, there is less of a need for a model to fit the data comprehensively.
On that count, the attached .49-.64 $R^{2}$ values are not concerning.
However, further analysis of the residuals demonstrates weaknesses in model selection.
Figure \@ref(fig:linearesid) shows the residuals against fitted values for the full-sample, fixed-effects model.
Ideally, residuals show no conclusive pattern, and are independent against the fitted values.
Here, there is a clear inverse relationship framed by the bounds of the Republican voting share at 0 and 100 percent.
Linear models are not built to handle bounded response variables, though I used one for the ease of computation and interpretation.

``` {r linear, echo=FALSE, out.width='45%', fig.align='center', fig.cap="Diagnostic plots of the linear models.", fig.subcap=c("Residuals of full linear model.\\label{fig:linearesid}","Acutal vs. fitted quantiles of full linear model.\\label{fig:linearquant}")}
include_graphics(c("figure/linearesid.png", "figure/linearquant.png"))
```

In order to validate the results of these models, I also modeled Republican vote share by different distributions.
I settled on reporting results for regressions on the Beta distribution because of its flexibility and ability to approximate the distribution of Republican voting share.
The Beta distribution is a basic (but complicated) distribution used for response variables bounded between 0 and 1.
It easily incorporates changing variance and does not assume linearity, which is helpful when considering social interactions generally, and electoral data specifically.
As Figure \@ref(fig:linearquant) shows, the variance of actual versus fitted values skyrockets at the upper end of my model.

``` {r betaresid, echo=FALSE, out.width='90%', fig.align='center', fig.cap="Residuals of beta regression."}
include_graphics("figure/betaresid.png")
```

In contrast, the behavior of Figure \@ref(fig:betaresid) conforms more closely to an ideal distribution, with less-pronounced upper and lower bounds.
Results of the beta regressions can be seen in Table \@ref(tab:beta).
Coefficients are altogether similar to what the linear models predict, making me more secure in my belief of their validity.


```{r beta, echo=FALSE, results='asis', eval=FALSE}
mod8 <- betareg(ADJ_RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, mutate_at(wide, vars(ADJ_PRICE07, ANXIETY, ADJ_FORQ, EMPLOYRISK, UNEMCHG, UNEM10, MEDHHI, DENSITY, TENURE, TENURE2, OLD, VAP_B, VAP_H, VAP_H2, VAP_W, WHITESOMECOL, EVANRATE, LDSRATE), funs(./100)))
mod9 <- betareg(ADJ_RPCT ~ NSP1 + ADJ_PRICE07*ANXIETY + ADJ_PRICE07*ADJ_FORQ + ADJ_PRICE07*EMPLOYRISK + UNEMCHG + UNEM10 + MEDHHI + ADJ_FORQ*DENSITY + TENURE + TENURE2 + OLD + VAP_B + VAP_H + VAP_H2 + VAP_W*WHITESOMECOL + EVANRATE + LDSRATE + STATE, mutate_at(filter(wide, RESULT != "EXTRA-TP"), vars(ADJ_PRICE07, ANXIETY, ADJ_FORQ, EMPLOYRISK, UNEMCHG, UNEM10, MEDHHI, DENSITY, TENURE, TENURE2, OLD, VAP_B, VAP_H, VAP_H2, VAP_W, WHITESOMECOL, EVANRATE, LDSRATE), funs(./100)))
stargazer(mod8, mod9, type = "latex", title = "Beta regression of NSP1 on Voting", omit = c("^STATE"), label = "tab:beta", df = F, align = T, report = "vc*", header = F, add.lines = list(c("State fixed Effects?", "Y", "Y")), digits = 4, no.space = T, covariate.labels = c(NA, "Home price index change, 2007-2010", "Economic anxiety", "2010 forelcosure rate", "Labor risk", "Unemployment change `05--`10", "2010 unemployment rate", "Median household income (000s)", "Population density (per sq.mi.)", "Tenure in home", "Squared tenure", "65-and-up \\%", "Black \\%", "Hispanic \\%", "Hispanic \\% squared", "White \\%", "White: some college or less \\%", "Evangelical \\%", "L.D.S. \\%", "Price change $\\times$ anxiety", "Price change $\\times$ foreclosure rate", "Price change $\\times$ labor risk", "Foreclosure rate $\\times$ density", "White \\% $\\times$ some college or less"), dep.var.labels = "Republican vote percentage")
```

Lastly, as mentioned, I believe these models were spatially-dependent, which biased the estimation of the home price effect on voting behavior.
Using state-level fixed effects and tract-level housing prices corrected some of this behavior, but the local nature of politics cannot be underestimated.
I had originally planned to incorporate spatial autoregressive methods to correct for this spatial dependence, but limitations inherent to my data, as well as a lack of remote access to better hardware, quashed that opportunity.[^This chapter was completed during 2020's novel coronavirus pandemic, which restricted access to University resources.]
Nonetheless, I can prove the presence of spatial dependence in my models to highlight future areas for exploration.

I first constructed a matrix of neighboring census tracts using geographic tract files; this matrix tells **R** which tracts are neighbors by triangulating their population-weighted geographic centers.
I then ran the residuals of each model (from a positivist interpretation, these are the unobserved variables) through Moran's I and Geary's C tests.
The similar tests look for spatial dependence respectively at the global and local levels.
Since this dataset is fractured, containing large discontiguities, Geary's C test will be the more appropriate measure; both are retained because the calculations are quick and similar.
Table \@ref(tab:spdep) displays the results of these tests, all of which reject the null hypothesis of no spatial dependence **R**.

```{r spdep, echo=FALSE, message=FALSE}
spdep <- read_csv("data/voting/display/spdep.csv")
kable(spdep, "latex", booktabs = T, caption = "Results of various tests for spatial dependence. In all tests, the null hypothesis is spatially-independent.", align = 'c')
```

## Conclusion
In sum, 2010 prices were negatively associated with the Neighborhood Stabilization Program's first round of funding.
This fact may be due to unobserved variable bias, but, given the normalcy of regression diagnostics, it may instead be due to the NSP's timeline.
Due to the mandate that grantees purchase homes at a slight discount, there may not have been enough time to clear, repair, and re-appraise (or fully resell) properties by the 2010 midterms.
My results indicate that the NSP reduced prices between 1.3% and 2.0%, a small reduction keeping with size of the mandated discount.
Further, by NSP1's maturation in 2013, the amount of funds spent on acquisitions dropped, while new construction and rehabilitation increased slightly compared to its 2010 progress.[@185682010hud; @hud2013hud]
The negative impact had by the first round of the Neighborhood Stabilization Program (the only round mature enough to even consider) on prices means that the NSP could not have had the effect in question in 2010.

The labor risk--equity model was evaluated despite this fact, and evidence suggested the theorized effects were present in the 2010 midterms, especially when only Tea Party tracts are considered.
Economic anxiety, composed of low equity---represented by high foreclosure rates---and risky employment---represented by high variance of unemployment rate---magnified the conservatizing effects of increased home prices.
These results were statistically significant and robust to several covariates.
Still to be explained are the mechanisms by which labor risk propagates through mortgage markets, HELOCs, and political behavior.
These variables provided "liberalizing" effects on voters (though not when combined with high foreclosure rates), confounding prior literature on the subject.

Limitations of the measurement and statistical methods were explored, with strong evidence that further work is needed to extricate the impacts studied from spatial dependence and bounded response assumptions.
Beta distribution regression was employed to correct for the latter issue, with slightly more ideal measures of model fitness and similarly strong evidence for the labor risk--equity model's capacity to explain voter behavior in the full sample as well as the Tea Party tracts in particular.
These results build towards consensus with empirical literature, girding Ansell (2014) with voting results to provide a crucial middle step in his argument.
