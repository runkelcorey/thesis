---
bibliography: bib/thesis.bib
csl: csl/chicago-note-bibliography.csl
output:
  pdf_document:
    keep_tex: true
  html_document: default
  word_document: default
---
# Effects of the Neighborhood Stabilization Program on Voting {#outcome}

With this model in hand, I turn now to its application.
My approach is simple but intensive: connect the votes for Republican House of Representatives candidates to foreclosure rates---taken with other variables as a rough proxy of home equity---at the Census tract level.
Logically, this approach nestles within that of Ansell 2014.
That paper connected home prices to local sentiments regarding government policies, and then looked at policies after those sentiment polls were conducted.
It imputed that, if there existed sentiments favoring less social insurance, followed by policies which enacted less social insurance, then those sentiments filtered through the voting and public opinion apparatus to produce those policies.
While Ansell's assumption that there were no significant confounding factors may have been correct, his methodology was not rigorous, as it neglected the middle step of actually voting for politicians inclined towards such measures.
My approach searches for just that---votes associated with housing prices and/or foreclosure relief policies.

Data complete with every variable in my model was available for 53.7% of the populated census tracts of 24 states, including 54.8% of those census tracts where a self-described member of the Tea Party ran for election.
Most of the remaining census tracts belonged to states where it was not feasible to connect voting returns with census geography.
For instance, Michigan does not make clear the links between a voting tabulation district (VTD) as the Census Bureau defines it, and the county-precinct-ward system the state uses to publicize its results.
For 15 other states, including Illinois, elections are so devolved that a state-wide election aggregation would have taken days to collect.
A full tabulation of data coverage is available in Table \@ref(tab:coverage).

Most of the data came, in one way or another, from the US Census Bureau.
Since 1990, the Census Bureau has delineated census blocks covering the entire United States, standardizing units of analysis and making trivial the aggregation of data at various granularity.
However, some key variables in this analysis come from outside the Census Bureau, from state governments, other federal agencies, and independent researchers, each of which uses different geographical units.
To understand the construction of this novel dataset, it is important to first understand the relationships between different statistical geographies.

## Relationships between statistical geographies {#census-geography}
The basic Census geography runs as follows (see Figure \@ref(fig:geography) for the Census Bureau's graphical representation).
The basic unit, blocks, are designed for Census takers to walk; they are optimized for population but constrained by physical boundaries difficult or illogical to cross.
Blocks are then aggregated into census tracts (my unit of analysis): tracts contain between 1,200 and 8,000 people, and are the smallest unit for which American Community Survey data---such as median household income and educational attainment---are published.
Census tracts sit inside counties and then inside states; unlike tracts and blocks, county boundaries are also legal jurisdictions and therefore rarely change.

While tracts and blocks were *designed* to be semi-permanent, and to act as the basis for other, non-Census areas, in practice their shapes shift with population changes.
These shifts mean that: not all 2000 tracts and 2010 tracts are exactly the same (though many are); and non-Census areas (such as state-designed VTDs) can cut census blocks.
Since these Census Bureau does not make public the responses of individual persons or homes until several decades after, placing each record in its appropriate area is impossible.
Rather, ecological methods approximate the distribution of persons, votes, or homes among geographies.
Ecological methods assume that persons, votes, or homes are equally distributed throughout an area: ecological methods would assume, for instance, that since six percent of Americans are millionaires, then six out of every hundred persons sampled---no matter their neighborhood---would be millionaires.
Strictly speaking, ecological methods are logical fallacies of de-composition, of taking the whole for the part.
However, guided by the right principles, ecological methods can be perfectly valid statistical tools.

The first principle is that smaller geographies are better.
Take for example tract 12099005947, a nearly-optimal tract of 4,406 people in Palm Beach County.
The owner occupation rate is 97%, and 88% of the residents are aged 65 or older.
However, Palm Beach County entire contains tracts with as low as 4% 65-and-up, and owner occupancy rates around 33%.
Taking the county for the tract would poorly represent the diversity of life within Palm Beach, smoothing out the nuances that differentiate one neighborhood's politics from the next.
Zooming in on census tracts improves the accuracy of ecological methods, allowing for a better picture

The second principle is that errors should be distributed evenly.
Errors here refers to the process by which some geographies must be decomposed and recomposed in order to translate non--2010 Census geography into 2010 Census geography.
This assumption may not always hold in my data: the history of American urban planning has shown that physical barriers---the same used to bound census blocks---often bind communities in more ways than one.
That being said, the supposed problem of partisan gerrymandering should be a moot point.
Gerrymandering operates on the state level, assigning particular voting precincts to particular Congressional districts.
Since my analysis deals with already-made and locally-created voting precincts, it skirts this particular problem.
I again rely on the granularity of this data for its validity, but without a secondary source of data (such as Zillow's or Redfin's proprietary sources), the accurate distribution of Neighborhood Stabilization Program data (which was enumerated in 2000 Census geography) will remain unknown.

The last principle is that data should be extensive.
This idea is native to all statistical inquiry, with the logic being that evenly-distributed errors will sort themselves out in large enough groups.
In this regard I have succeeded, with a 1/2 sample of the relevant elections totaling 26,550 census tracts (with an almost even-sized control group for state-level fixed effects).
To be fully open to criticism, however, I will describe the data aggregation and de/recomposition methods for each variable in my analysis.

## Data collection and aggregation
I built my data almost exclusively from official statistics and estimates.
Given that most of my sources would eventually lead back to the Census Bureau, which covers the entire United States, I knew that the factors limiting my coverage would lie outside the Census Bureau.
Collecting and translating precinct-level voting data to census tracts proved to be the most limited and time-consuming aspect of this process.
I began by downloading precinct-level voting returns from the Harvard Election Data Archive (HEDA),[@ansolabehere2014precinctlevel] started in 2008 by political science researchers.
This database compiled voting returns from most states and reported results for state and national races in a standardized format.

I then wedded these figures to files specifying the geographic boundaries of each voting precinct within a state.
At this stage saw the complete loss of several states' data as the system used to identify precincts at the state-level was inconsistent with Census Bureau naming conventions.
For each state, I looked for an isomorphic mapping between geographic specifications and voting returns, and only for links where the match was clear were the data used.
Case in point was Maryland: the voting returns data clearly contained every single specified tract in Maryland, but matching algorithms could only identify a few hundred of the several thousand voting districts.
Geographic files came primarily from the Census Bureau's TIGER/Line redistricting project, the official database for all Census geography,[@20122010] via the Election-Geodata mapping project, an open-source repository for redistricting data.[@kelso2020nvkelso]

